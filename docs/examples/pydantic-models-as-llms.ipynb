{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using Pydantic Models as LLM Clients**\n",
    "\n",
    "One of the most fun additions I've made to `zyx` is the ability to directly generate & work with `Pydantic` models, through the specialized `BaseModel` provided by the library, that has been deeply integrated with LLM methods.\n",
    "\n",
    "These methods bring in a new level of integration between LLMs & `Pydantic` models, allowing for a more seamless experience when working with structured data. Some of the power this implementation brings includes:\n",
    "\n",
    "```\n",
    "\n",
    "- **Chain of Thought** by seqentially generating Pydantic fields\n",
    "- Instantly Generating Synthetic Data from Pydantic Models\n",
    "- Making Patches/Edits to Specific Fields\n",
    "- Using Content in Pydantic Models as Context for Completions (**RAG!**)\n",
    "- Generating content directly into a specific Pydantic field\n",
    "- & more! :)\n",
    "\n",
    "```\n",
    "\n",
    "Let's dive into some examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "## **What functions are available?**\n",
    "\n",
    "All functions available on `BaseModel` are prefixed with `model_`. The available functions are:\n",
    "\n",
    "- `model_generate()`\n",
    "- `model_regenerate()`\n",
    "- `model_completion()`\n",
    "- `model_patch()`\n",
    "- `model_select()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating Synthetic Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data from a Pydantic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate data from a Pydantic model, you can use the `model_generate` method. This method will generate a single instance of the model.\n",
    "\n",
    "The reason the methods are prefixed with `model_` is because `Pydantic` themselves use `model_` for their methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Data from a Pydantic Model\n",
    "from zyx import BaseModel\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "# any litellm model will work\n",
    "User.model_generate(model = \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Batch Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same method, you can generate a batch of data by passing in the `n` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Batch Data \n",
    "from zyx import BaseModel\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "User.model_generate(model = \"gpt-4o-mini\", n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chain of Thought**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model_generate` supports a `sequential` generation mode, which allows you to generate data field by field, in a chain of thought manner.\n",
    "\n",
    "This is useful when you want to generate data that adheres to a specific schema, but where each field is generated based on the previous fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of Thought\n",
    "from zyx import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class ComplexSolution(BaseModel):\n",
    "    equation: str\n",
    "    process: Optional[str] = None\n",
    "    reasoning: Optional[str] = None\n",
    "    answer: Optional[int] = None\n",
    "\n",
    "# basemodels can be used normally\n",
    "complex_solution = ComplexSolution(\n",
    "    equation = \"x^2 + 2x + 1\"\n",
    ")\n",
    "\n",
    "# generate the data\n",
    "# process is \"batch\" by default\n",
    "complex_solution = complex_solution.model_generate(\n",
    "    model = \"gpt-4o-mini\", process = \"sequential\")\n",
    "\n",
    "print(complex_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regenerating Specific Fields**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Content in Pydantic Models as Context for Completions (RAG!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea8fb000fdb48828e18cc43b0ff2092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Based on your context, it seems like you really like apples.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Based on your context, it seems like you really like apples.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using Content in Pydantic Models as Context for Completions (RAG!)\n",
    "context = [\n",
    "    \"i really like apples\",\n",
    "    \"some people like oranges more\",\n",
    "    \"bananas are yellow\",\n",
    "    \"some people like bananas\",\n",
    "]\n",
    "\n",
    "# dumb example i know\n",
    "from zyx import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class Context(BaseModel):\n",
    "    context : List[str]\n",
    "\n",
    "# lets fill in our model\n",
    "context_model = Context(\n",
    "    context = context,\n",
    ")\n",
    "\n",
    "# get the completion\n",
    "# using .model_completion()\n",
    "answer = context_model.model_completion(\"what is my favorite fruit?\")\n",
    "\n",
    "# BaseModel.completion() returns the same `ChatCompletion` instance as zyx.completion()\n",
    "# lets print the content\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Fields for Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Fields for Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Autogenerating `Patches`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autogenerating `Patches`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Making Selections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Selections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
