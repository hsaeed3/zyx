"""zyx.ai.models.embeddings.types"""

from __future__ import annotations

from typing import Literal, TypeAlias, TypeAliasType

from pydantic import BaseModel
from openai.types.create_embedding_response import CreateEmbeddingResponse

__all__ = ["EmbeddingModelResponse", "EmbeddingModelSettings"]


EmbeddingModelResponse: TypeAlias = CreateEmbeddingResponse
"""Alias representation of a response generated by an embedding
model. This is the direct `CreateEmbeddingResponse` type from
the OpenAI Python SDK.
"""


EmbeddingModelName = TypeAliasType(
    "EmbeddingModelName",
    Literal[
        "openai/text-embedding-3-small",
        "openai/text-embedding-3-large",
        "openai/text-embedding-ada-002",
        # local
        "ollama/embeddinggemma",
        "ollama/nomic-embed-text",
        "ollama/mxbai-embed-large",
        "ollama/bge-m3",
        "ollama/all-minilm",
        "ollama/snowflake-arctic-embed",
        "ollama/snowflake-arctic-embed2",
        "ollama/bge-large",
        "ollama/paraphrase-multilingual",
        "ollama/granite-embedding",
        "ollama/qwen3-embedding",
    ],
)
"""Alias for common embedding model names. Unlike the LanguageModelName
alias, this contains only OpenAI's embedding models, and a collection of the
most popular local embedding models from Ollama. 
When using embedding models, (if your hardware permits it), you should prefer to use
them locally!
"""


class EmbeddingModelSettings(BaseModel):
    """Simple configuration representation for an
    embedding model.

    This class excludes the actual model definition as well
    as the on-invocation input content.
    """

    dimensions: int | None = None
    """The number of dimensions the resulting output embeddings should have."""

    encoding_format: Literal["float", "base64"] | None = None
    """The format to return the embeddings in."""

    user: str | None = None
    """A unique identifier representing your end-user, which can help OpenAI to monitor
    and detect abuse."""
